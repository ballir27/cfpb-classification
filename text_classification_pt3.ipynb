{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31f75184",
   "metadata": {},
   "source": [
    "# Classification of Consumer Complaints\n",
    "\n",
    "The Consumer Financial Protection Bureau publishes the Consumer Complaint Database, a collection of complaints about consumer financial products and services that were sent to companies for response. Complaints are published after the company responds, confirming a commercial relationship with the consumer, or after 15 days, whichever comes first. \n",
    "\n",
    "You have been provided with a dataset of over 350,000 such complaints for 5 common issue types. Your goal is to train a text classification model to identify the issue type based on the consumer complaint narrative. The data can be downloaded from https://drive.google.com/file/d/1Hz1gnCCr-SDGjnKgcPbg7Nd3NztOLdxw/view?usp=share_link \n",
    "\n",
    "At the end of the project, your team should should prepare a short presentation where you talk about the following:\n",
    "* What steps did you take to preprocess the data?\n",
    "* How did a model using unigrams compare to one using bigrams or trigrams?\n",
    "* How did a count vectorizer compare to a tfidf vectorizer?\n",
    "* What models did you try and how successful were they? Where did they struggle? Were there issues that the models commonly mixed up?\n",
    "* What words or phrases were most influential on your models' predictions?\n",
    "\n",
    "**Bonus:** A larger dataset containing 20 additional categories can be downloaded from https://drive.google.com/file/d/1gW6LScUL-Z7mH6gUZn-1aNzm4p4CvtpL/view?usp=share_link. How well do your models work with these additional categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07044091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e7bdfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = pd.read_csv('../data/complaints_sentimentscore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62b88d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>narrative</th>\n",
       "      <th>issue</th>\n",
       "      <th>review_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My name is XXXX XXXX this complaint is not mad...</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>0.7398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I searched on XXXX for XXXXXXXX XXXX  and was ...</td>\n",
       "      <td>Fraud or scam</td>\n",
       "      <td>-0.7457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          narrative  \\\n",
       "0           0  My name is XXXX XXXX this complaint is not mad...   \n",
       "1           1  I searched on XXXX for XXXXXXXX XXXX  and was ...   \n",
       "\n",
       "                                  issue  review_sentiment  \n",
       "0  Incorrect information on your report            0.7398  \n",
       "1                         Fraud or scam           -0.7457  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f9cc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping it simple for now.  In the next notebook I will look at bi and trigrams..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4373c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = complaints[['narrative', 'review_sentiment']]\n",
    "y = complaints['issue']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab346a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "\n",
    "X_train_vec = vect.fit_transform(X_train['narrative'])\n",
    "X_test_vec = vect.transform(X_test['narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1be8fa75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<265074x72222 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21821225 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a955a21",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2186742284.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[26], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    'clf__fit_prior':[False, True]\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "clf = MultinomialNB()\n",
    "\n",
    "pipe = Pipeline([(\"vect\", vect), (\"clf\", clf)])\n",
    "\n",
    "param_grid = {\n",
    "    'vect__ngram_range':[(1,1), (1,2), (1,3)],\n",
    "    'vect__min_df':[1, 2, 5, 10, 20],\n",
    "    'clf__fit_prior':[False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646d1dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB().fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02716d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7988976663120487\n",
      "[[12086  2039   500  3343   323]\n",
      " [  587  4476    51   112    85]\n",
      " [   67    55  2813   110    42]\n",
      " [ 6610  1046   834 46997  1839]\n",
      " [   36    40    12    38  4217]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67a7f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above is interesting, but not really what's needed.  Probably need to one encode and then look for true false?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11afcba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true predictions: 70589\n",
      "Number of false predictions: 17769\n"
     ]
    }
   ],
   "source": [
    "true_predictions=y_test==y_pred\n",
    "false_predictions=y_test!=y_pred\n",
    "\n",
    "print('Number of true predictions:', np.sum(true_predictions))\n",
    "print('Number of false predictions:', np.sum(false_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cbbb55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = complaints[['review_sentiment']]\n",
    "y = complaints['issue']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 321, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb48ed2",
   "metadata": {},
   "source": [
    "Naive Bayes can't use negative values, so switching to Randomforest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a24fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffa7cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41ab5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dd66883",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffb0ca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.639760972407705\n",
      "[[ 2586   233    85 15210   177]\n",
      " [  613   117    25  4494    62]\n",
      " [  334    52    24  2625    52]\n",
      " [ 2752   321   174 53730   349]\n",
      " [  530    76    44  3622    71]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c92342d",
   "metadata": {},
   "source": [
    "Overall, not as well as unigrams, but still reasonably well, at 63%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e53be3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of true predictions: 56528\n",
      "Number of false predictions: 31830\n"
     ]
    }
   ],
   "source": [
    "true_predictions=y_test==y_pred\n",
    "false_predictions=y_test!=y_pred\n",
    "\n",
    "print('Number of true predictions:', np.sum(true_predictions))\n",
    "print('Number of false predictions:', np.sum(false_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b4f83",
   "metadata": {},
   "source": [
    "this notebook focused on looking at predictors using a sparse matrix/unigram modeling.  We also used the sentiment analysis. We did not tune any of the models. In the next notebook, we will look at other text features, such as bi and trigram's and perhaps tokenizing by sentence..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d1426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
